import os
import io
import logging
import asyncio
import textwrap
import psycopg2
from pathlib import Path
from typing import List, Tuple

import fitz  # PyMuPDF
import pytesseract
import streamlit as st
import requests
from PIL import Image
from dotenv import load_dotenv

from langchain_ollama import OllamaEmbeddings, OllamaLLM
from langchain.docstore.document import Document
from langchain_chroma import Chroma
from langchain.prompts import PromptTemplate
from langchain.schema import LLMResult

# ENV LOGGING 
PROJECT_ROOT = Path(__file__).resolve().parent
load_dotenv(PROJECT_ROOT / ".env", override=True)
logging.basicConfig(level=logging.INFO,
                    format="%(asctime)s | %(levelname)8s | %(message)s")

BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN", "")
DB_URI    = os.getenv("POSTGRES_URI", "")
BAD_WORDS = {"badword1", "badword2", "badword3"}

# PostgreSQL –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ 
def init_db():
    if not DB_URI:
        return
    try:
        with psycopg2.connect(DB_URI) as conn, conn.cursor() as cur:
            cur.execute("""
                CREATE TABLE IF NOT EXISTS logs (
                    id SERIAL PRIMARY KEY,
                    chat_id BIGINT,
                    question TEXT,
                    answer TEXT,
                    model TEXT,
                    temperature FLOAT,
                    bad_words TEXT[],
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                );
            """)
            conn.commit()
    except Exception as e:
        logging.error("–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã –≤ PostgreSQL: %s", e)


def log_to_db(chat_id: int, question: str, answer: str, model: str, temperature: float, bad_words: List[str]):
    if not DB_URI:
        return
    try:
        with psycopg2.connect(DB_URI) as conn, conn.cursor() as cur:
            cur.execute("""
                INSERT INTO logs (chat_id, question, answer, model, temperature, bad_words)
                VALUES (%s, %s, %s, %s, %s, %s);
            """, (chat_id, question, answer, model, temperature, bad_words))
            conn.commit()
    except Exception as e:
        logging.error("–û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ –≤ PostgreSQL: %s", e)

#UI TEXTS
UI_TEXTS = {
    "–†—É—Å—Å–∫–∏–π": {
        "title": "üìÑ PDF-–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä",
        "upload": "–ó–∞–≥—Ä—É–∑–∏—Ç–µ PDF-—Ñ–∞–π–ª",
        "question": "–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –≤–æ–ø—Ä–æ—Å –∫ –¥–æ–∫—É–º–µ–Ω—Ç—É:",
        "analyze": "üîç –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å",
        "bad_words": "‚ö†Ô∏è –ó–∞–ø—Ä–µ—â—ë–Ω–Ω—ã–µ —Å–ª–æ–≤–∞: ",
        "extracting": "üìú –ß–∏—Ç–∞–µ–º PDF‚Ä¶",
        "indexing": "üî¨ –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º‚Ä¶",
        "answer": "‚úÖ –û—Ç–≤–µ—Ç:",
        "download": "üíæ –°–∫–∞—á–∞—Ç—å –æ—Ç–≤–µ—Ç.txt",
        "model": "LLM –º–æ–¥–µ–ª—å",
        "creativity": "–ö—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å (temperature)",
        "chat_id": "–í–≤–µ–¥–∏—Ç–µ –≤–∞—à Telegram chat ID (—á–∏—Å–ª–æ):",
        "invalid_id": "‚ùó –°–Ω–∞—á–∞–ª–∞ —É–∫–∞–∂–∏—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π Telegram ID ‚Äî —Ç–æ–ª—å–∫–æ —Ü–∏—Ñ—Ä—ã.",
    },
    "English": {
        "title": "üìÑ PDF Analyzer",
        "upload": "Upload PDF file",
        "question": "Enter your question about the document:",
        "analyze": "üîç Analyze",
        "bad_words": "‚ö†Ô∏è Forbidden words: ",
        "extracting": "üìú Reading PDF‚Ä¶",
        "indexing": "üî¨ Indexing‚Ä¶",
        "answer": "‚úÖ Answer:",
        "download": "üíæ Download answer.txt",
        "model": "LLM model",
        "creativity": "Creativity (temperature)",
        "chat_id": "Enter your Telegram chat ID (number):",
        "invalid_id": "‚ùó Please enter a valid numeric Telegram chat ID first.",
    },
    "“ö–∞–∑–∞“õ—à–∞": {
        "title": "üìÑ PDF —Ç–∞–ª–¥–∞—É—à—ã—Å—ã",
        "upload": "PDF —Ñ–∞–π–ª–¥—ã –∂“Ø–∫—Ç–µ“£—ñ–∑",
        "question": "“ö“±–∂–∞—Ç“õ–∞ “õ–∞—Ç—ã—Å—Ç—ã —Å“±—Ä–∞“ì—ã“£—ã–∑–¥—ã –µ–Ω–≥—ñ–∑—ñ“£—ñ–∑:",
        "analyze": "üîç –¢–∞–ª–¥–∞—É",
        "bad_words": "‚ö†Ô∏è –†“±“õ—Å–∞—Ç –µ—Ç—ñ–ª–º–µ–≥–µ–Ω —Å”©–∑–¥–µ—Ä: ",
        "extracting": "üìú PDF –æ“õ—ã–ª—ã–ø –∂–∞—Ç—ã—Ä‚Ä¶",
        "indexing": "üî¨ –ò–Ω–¥–µ–∫—Å—Ç–µ—É‚Ä¶",
        "answer": "‚úÖ –ñ–∞—É–∞–ø:",
        "download": "üíæ –ñ–∞—É–∞–ø—Ç—ã –∂“Ø–∫—Ç–µ—É",
        "model": "LLM –º–æ–¥–µ–ª—ñ",
        "creativity": "–ö—Ä–µ–∞—Ç–∏–≤—Ç—ñ–ª—ñ–∫ (temperature)",
        "chat_id": "Telegram chat ID –µ–Ω–≥—ñ–∑—ñ“£—ñ–∑ (—Ç–µ–∫ —Å–∞–Ω):",
        "invalid_id": "‚ùó –ê–ª–¥—ã–º–µ–Ω –¥“±—Ä—ã—Å Telegram chat ID –µ–Ω–≥—ñ–∑—ñ“£—ñ–∑ ‚Äî —Ç–µ–∫ —Å–∞–Ω–¥–∞—Ä.",
    }
}

#HELPERS

def send_telegram(chat_id: int, text: str, inline: bool = False) -> None:
    if not BOT_TOKEN or not chat_id:
        return
    for chunk in (text[i:i + 4000] for i in range(0, len(text), 4000)):
        try:
            req = {
                "chat_id": chat_id,
                "text": chunk,
                "parse_mode": "Markdown",
            }
            if inline:
                req["reply_markup"] = {
                    "inline_keyboard": [[{
                        "text": "‚è© –ó–∞–¥–∞—Ç—å –Ω–æ–≤—ã–π –≤–æ–ø—Ä–æ—Å",
                        "callback_data": "new_question"
                    }]]
                }
            requests.post(f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage", json=req, timeout=10)
        except Exception as exc:
            logging.error("Telegram error: %s", exc)


def extract_pages(uploaded) -> List[Tuple[str, int]]:
    pdf = fitz.open(stream=uploaded.read(), filetype="pdf")
    pages = []
    for i, page in enumerate(pdf, start=1):
        text = page.get_text("text").strip()
        if not text:
            pix = page.get_pixmap(dpi=300)
            img = Image.open(io.BytesIO(pix.pil_tobytes()))
            text = pytesseract.image_to_string(img, lang="rus+eng")
        pages.append((text, i))
    return pages


def chunk_pages(pages: List[Tuple[str, int]], chars_per_chunk: int = 1500) -> List[Document]:
    docs: List[Document] = []
    for text, page_num in pages:
        for chunk in textwrap.wrap(text, chars_per_chunk, break_long_words=False):
            meta = {"page": page_num}
            docs.append(Document(page_content=chunk, metadata=meta))
    return docs


def find_bad_words(text: str) -> List[str]:
    lowered = text.lower()
    return [w for w in BAD_WORDS if w in lowered]


#UI LAYOUT

def main():
    init_db()
    st.set_page_config(page_title="PDF‚Äë–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä", page_icon="üìÑ", layout="centered")

    lang = st.selectbox("UI language / –¢—ñ–ª / –Ø–∑—ã–∫", ("–†—É—Å—Å–∫–∏–π", "English", "“ö–∞–∑–∞“õ—à–∞"))
    txt = UI_TEXTS[lang]

    st.title(txt["title"])

    chat_id_str = st.text_input(txt["chat_id"])
    if not chat_id_str.strip().isdigit():
        st.info(txt["invalid_id"])
        st.stop()
    chat_id = int(chat_id_str.strip())

    model_name = st.selectbox(txt["model"], ("llama3.2:latest", "mistral:instruct", "phi3:mini"))
    temperature = st.slider(txt["creativity"], 0.0, 1.2, 0.2, 0.05)

    uploaded_file = st.file_uploader(txt["upload"], type=["pdf"])
    if not uploaded_file:
        st.stop()

    question = st.text_input(txt["question"])
    if not question:
        st.stop()

    if st.button(txt["analyze"]):
        bad = find_bad_words(question)
        if bad:
            warn = f"{txt['bad_words']}{', '.join(bad)}"
            st.warning(warn)
            send_telegram(chat_id, warn)

        with st.status(txt["extracting"], expanded=False):
            pages = extract_pages(uploaded_file)
            st.write(f"–ò–∑–≤–ª–µ—á–µ–Ω–æ —Å—Ç—Ä–∞–Ω–∏—Ü: {len(pages)}")

        with st.status(txt["indexing"], expanded=False):
            docs = chunk_pages(pages)
            embeddings = OllamaEmbeddings(model="nomic-embed-text")
            vectordb = Chroma.from_documents(docs, embeddings, persist_directory=".cache/chroma")
            retriever = vectordb.as_retriever(search_kwargs={"k": 5})
            st.write("–ß–∞–Ω–∫–æ–≤ –≤ –∏–Ω–¥–µ–∫—Å–µ:", len(docs))

        context_docs = retriever.get_relevant_documents(question)
        cited_context = "\n\n".join([
            f"[—Å—Ç—Ä. {d.metadata['page']}]:\n{d.page_content}" for d in context_docs
        ])
        prompt_text = (
            "–ò—Å–ø–æ–ª—å–∑—É–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ PDF (—Å —É–∫–∞–∑–∞–Ω–∏–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü) –∏ –æ—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å."
            " –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç–∞ –Ω–µ—Ç –≤ —Ç–µ–∫—Å—Ç–µ ‚Äî —Å–∫–∞–∂–∏ –æ–± —ç—Ç–æ–º.\n\n"
            f"–ö–æ–Ω—Ç–µ–∫—Å—Ç:\n{cited_context}\n\n–í–æ–ø—Ä–æ—Å: {question}"
        )

        llm = OllamaLLM(model=model_name, temperature=temperature)
        prompt = PromptTemplate(
            template="""{input}\n\n–û—Ç–≤–µ—Ç—å –Ω–∞ —Ä—É—Å—Å–∫–æ–º, —É–∫–∞–∑—ã–≤–∞—è –Ω–æ–º–µ—Ä–∞ —Å—Ç—Ä–∞–Ω–∏—Ü –≤ –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã—Ö —Å–∫–æ–±–∫–∞—Ö.""",
            input_variables=["input"],
        )
        chain = prompt | llm

        send_telegram(chat_id, "üß† –ú–æ–¥–µ–ª—å –¥—É–º–∞–µ—Ç‚Ä¶")
        with st.spinner("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞‚Ä¶"):
            answer: str = chain.invoke({"input": prompt_text})

        st.success(txt["answer"])
        st.write(answer)
        st.download_button(txt["download"], answer.encode("utf-8"), file_name="answer.txt")
        send_telegram(chat_id, f"‚úÖ –û—Ç–≤–µ—Ç:\n{answer}", inline=True)

        # PostgreSQL –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
        log_to_db(chat_id, question, answer, model_name, temperature, bad)

        st.caption(f"‚åõ –ó–∞–¥–µ–π—Å—Ç–≤–æ–≤–∞–Ω–∞ –º–æ–¥–µ–ª—å: {model_name} | –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞: {temperature}")


if __name__ == "__main__":
    main()